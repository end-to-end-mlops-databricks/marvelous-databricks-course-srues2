# This is a Databricks asset bundle definition for marvelous-databricks-course-srues2.
# The Databricks extension requires databricks.yml configuration file.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.

bundle:
  name: marvelous-databricks-course-srues2

artifacts:
  default:
    type: whl
    build: python -m build
    path: .

variables:
  root_path:
    description: root_path for the target
    default: /Shared/.bundle/${bundle.target}/${bundle.name}
  git_sha:
    description: git_sha
    default: abcd
  schedule_pause_status:
    description: schedule pause status
    default: UNPAUSED

resources:
  jobs:
    sleep-efficiency-model-update:
      name: sleep-efficiency-model-update-workflow
      schedule:
        quartz_cron_expression: "0 0 6 ? * MON"
        timezone_id: "Europe/Amsterdam"
        pause_status: ${var.schedule_pause_status}
      tags:
        project_name: "sleep-efficiency"
      job_clusters:
        - job_cluster_key: "sleep-efficiency-cluster"
          new_cluster:
            spark_version: "15.4.x-scala2.12"
            data_security_mode: "SINGLE_USER"
            node_type_id: "Standard_D4ds_v4"
            driver_node_type_id: "Standard_D4ds_v4"
            autoscale:
              min_workers: 2
              max_workers: 4
            azure_attributes:
              availability: SPOT_WITH_FALLBACK_AZURE

      tasks:
        - task_key: "preprocessing"
          job_cluster_key: "sleep-efficiency-cluster"
          # existing_cluster_id: 1014-134439-1sgb0b2m
          spark_python_task:
            python_file: "week5/preprocess.py"
          libraries:
           - whl: ./dist/*.whl
        - task_key: if_refreshed
          condition_task:
            op: "EQUAL_TO"
            left: "{{tasks.preprocessing.values.refreshed}}"
            right: "true"
          depends_on:
            - task_key: "preprocessing"

        - task_key: "train_model"
          depends_on:
            - task_key: "if_refreshed"
              outcome: "true"
          job_cluster_key: "sleep-efficiency-cluster"
          # existing_cluster_id: 1014-134439-1sgb0b2m
          spark_python_task:
            python_file: "week5/train_model.py"
            parameters:
              - "--job_run_id"
              - "{{job.id}}"
          libraries:
            - whl: ./dist/*.whl

        - task_key: "evaluate_model"
          depends_on:
            - task_key: "train_model"
          job_cluster_key: "sleep-efficiency-cluster"
          # existing_cluster_id: 1014-134439-1sgb0b2m
          spark_python_task:
            python_file: "week5/evaluate_model.py"
          libraries:
            - whl: ./dist/*.whl

        - task_key: model_update
          condition_task:
            op: "EQUAL_TO"
            left: "{{tasks.evaluate_model.values.model_update}}"
            right: "1"
          depends_on:
            - task_key: "evaluate_model"

        - task_key: "deploy_model"
          depends_on:
            - task_key: "model_update"
              outcome: "true"
          job_cluster_key: "sleep-efficiency-cluster"
          # existing_cluster_id: 1014-134439-1sgb0b2m
          spark_python_task:
            python_file: "week5/deploy_model.py"
          libraries:
            - whl: ./dist/*.whl

targets:
  dev:
    mode: development
    default: true
    workspace:
      host: https://adb-2004351416503484.4.azuredatabricks.net

  ## Optionally, there could be 'staging' or 'prod' targets here.
  #
  # prod:
  #   workspace:
  #     host: https://adb-2004351416503484.4.azuredatabricks.net
